{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_mappings(filename):\n",
    "    mappings = []\n",
    "\n",
    "    with open(filename) as f:\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "\n",
    "    cells = soup.find_all('Class')\n",
    "#---------get_mappings function-----\n",
    "#     for cell in cells:\n",
    "#         print(cell)\n",
    "#         entity1 = cell.get_attribute_list\n",
    "\n",
    "#         mappings.append(entity1)\n",
    "\n",
    "#     return mappings\n",
    "# get_mappings(path2)\n",
    "#------------with dataset---------\n",
    "    for class_ in cells:\n",
    "\n",
    "        data.append((class_.name.lower(), class_.is_a[0].name.lower(), \n",
    "                     get_path(class_).lower(),''.join(class_.label).lower(),''.join(class_.comment).lower()))\n",
    "\n",
    "        dataset = pd.DataFrame(data, columns=['Name','Parent','Path','label','comment'])\n",
    "        print(dataset)\n",
    "get_mappings('saref.rdf')   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "\n",
    "# Create a Graph\n",
    "g = Graph()\n",
    "\n",
    "# Parse in an RDF file hosted on the Internet\n",
    "g.parse('saref.rdf')\n",
    "print(f\"Graph g has {len(g)} statements.\")\n",
    "\n",
    "\n",
    "# Loop through each triple in the graph (subj, pred, obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2= 'OntoWind.owl'\n",
    "\n",
    "onto = get_ontology(path2)\n",
    "onto.load()\n",
    "\n",
    "# Read classes\n",
    "classes = []\n",
    "\n",
    "for cl in onto.classes():\n",
    "    classes.append(cl)\n",
    "    print(cl.name)\n",
    "classes = list(set(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pywsd\n",
      "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
      "     ---------------------------------------- 26.8/26.8 MB 5.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pywsd) (3.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pywsd) (1.18.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pywsd) (1.0.5)\n",
      "Collecting wn\n",
      "  Downloading wn-0.9.1-py3-none-any.whl (75 kB)\n",
      "     ---------------------------------------- 75.3/75.3 KB 4.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pywsd) (1.15.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from nltk->pywsd) (4.47.0)\n",
      "Requirement already satisfied: click in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from nltk->pywsd) (7.1.2)\n",
      "Requirement already satisfied: regex in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from nltk->pywsd) (2020.6.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from nltk->pywsd) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from pandas->pywsd) (2020.1)\n",
      "Requirement already satisfied: requests in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from wn->pywsd) (2.24.0)\n",
      "Collecting tomli\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from requests->wn->pywsd) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from requests->wn->pywsd) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from requests->wn->pywsd) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\abel teklearegay\\anaconda3\\lib\\site-packages (from requests->wn->pywsd) (3.0.4)\n",
      "Building wheels for collected packages: pywsd\n",
      "  Building wheel for pywsd (setup.py): started\n",
      "  Building wheel for pywsd (setup.py): finished with status 'done'\n",
      "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=9a9a009ff385a488cbc11556e2c6e055204c2ba183bc2c88f471e10e0f0a8377\n",
      "  Stored in directory: c:\\users\\abel teklearegay\\appdata\\local\\pip\\cache\\wheels\\cb\\a0\\90\\45c7b9e7e299efa69531bcf2b52a0fde612ec5a7b33a44ce89\n",
      "Successfully built pywsd\n",
      "Installing collected packages: tomli, wn, pywsd\n",
      "Successfully installed pywsd-1.2.4 tomli-2.0.1 wn-0.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pywsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wn==0.0.23\n",
      "  Downloading wn-0.0.23.tar.gz (31.6 MB)\n",
      "     ---------------------------------------- 31.6/31.6 MB 5.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wn\n",
      "  Building wheel for wn (setup.py): started\n",
      "  Building wheel for wn (setup.py): finished with status 'done'\n",
      "  Created wheel for wn: filename=wn-0.0.23-py3-none-any.whl size=31792926 sha256=e2c1624d94c0c60cf14a7598645ac3b8ae507ab7a26ce555f4e91f0298a8300f\n",
      "  Stored in directory: c:\\users\\abel teklearegay\\appdata\\local\\pip\\cache\\wheels\\6b\\eb\\fe\\eb7c7be28c29ee90dd9d6f58c116673d0eb07b2d83dfb72a37\n",
      "Successfully built wn\n",
      "Installing collected packages: wn\n",
      "  Attempting uninstall: wn\n",
      "    Found existing installation: wn 0.0.22\n",
      "    Uninstalling wn-0.0.22:\n",
      "      Successfully uninstalled wn-0.0.22\n",
      "Successfully installed wn-0.0.23\n"
     ]
    }
   ],
   "source": [
    "!pip install -U wn==0.0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WordNet' from 'wn' (C:\\Users\\Abel Teklearegay\\anaconda3\\lib\\site-packages\\wn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3f85230ac2b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpywsd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlesk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msimple_lesk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSentenceSimilarity\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pywsd\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet_30_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'WordNet' from 'wn' (C:\\Users\\Abel Teklearegay\\anaconda3\\lib\\site-packages\\wn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from pywsd.lesk import simple_lesk\n",
    "import numpy as np\n",
    "\n",
    "class SentenceSimilarity:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.word_order = False\n",
    "        \n",
    "    \n",
    "    def identifyWordsForComparison(self, sentence):\n",
    "        #Taking out Noun and Verb for comparison word based\n",
    "        tokens = nltk.word_tokenize(sentence)        \n",
    "        pos = nltk.pos_tag(tokens)\n",
    "        pos = [p for p in pos if p[1].startswith('N') or p[1].startswith('V')]     \n",
    "        return pos\n",
    "    \n",
    "    def wordSenseDisambiguation(self, sentence):\n",
    "        # removing the disambiguity by getting the context\n",
    "        pos = self.identifyWordsForComparison(sentence)\n",
    "        sense = []\n",
    "        for p in pos:\n",
    "            sense.append(simple_lesk(sentence, p[0], pos=p[1][0].lower()))\n",
    "        return set(sense)\n",
    "    \n",
    "    def getSimilarity(self, arr1, arr2, vector_len):\n",
    "        #cross multilping all domains \n",
    "        vector = [0.0] * vector_len\n",
    "        count = 0\n",
    "        for i,a1 in enumerate(arr1):\n",
    "            all_similarityIndex=[]\n",
    "            for a2 in arr2:\n",
    "                similarity = a1.wup_similarity(a2)\n",
    "                if similarity != None:\n",
    "                    all_similarityIndex.append(similarity)\n",
    "                else:\n",
    "                    all_similarityIndex.append(0.0)\n",
    "            all_similarityIndex = sorted(all_similarityIndex, reverse = True)\n",
    "            vector[i]=all_similarityIndex[0]\n",
    "            if vector[i] >= 0.804:\n",
    "                count +=1\n",
    "        return vector, count        \n",
    "        \n",
    "        \n",
    "    def shortestPathDistance(self, sense1, sense2):\n",
    "        #getting the shortest path to get the similarity\n",
    "        if len(sense1) >= len(sense2):\n",
    "            grt_Sense = len(sense1)\n",
    "            v1, c1 = self.getSimilarity(sense1, sense2, grt_Sense)\n",
    "            v2, c2 = self.getSimilarity(sense2, sense1, grt_Sense)\n",
    "        if len(sense2) > len(sense1):\n",
    "            grt_Sense = len(sense2)\n",
    "            v1, c1 = self.getSimilarity(sense2, sense1, grt_Sense)\n",
    "            v2, c2 = self.getSimilarity(sense1, sense2, grt_Sense)\n",
    "        return np.array(v1),np.array(v2),c1,c2\n",
    "        \n",
    "    def main(self, sentence1, sentence2):\n",
    "        sense1 = self.wordSenseDisambiguation(sentence1)\n",
    "        sense2 = self.wordSenseDisambiguation(sentence2)        \n",
    "        v1,v2,c1,c2 = self.shortestPathDistance(sense1,sense2)\n",
    "        dot = np.dot(v1,v2)\n",
    "        print(\"dot\", dot) # getting the dot product\n",
    "        tow = (c1+c2)/1.8\n",
    "        final_similarity = dot/tow\n",
    "        print(\"similarity\",final_similarity)\n",
    "\n",
    "obj = SentenceSimilarity()\n",
    "a = 'A jewel is a precious stone used to decorate valuable things that you wear, such as rings or necklaces.'\n",
    "b = 'A gem is a jewel or stone that is used in jewellery.'\n",
    "obj.main(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WordNet' from 'wn' (C:\\Users\\Abel Teklearegay\\anaconda3\\lib\\site-packages\\wn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c67d41550e26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'WordNet' from 'wn' (C:\\Users\\Abel Teklearegay\\anaconda3\\lib\\site-packages\\wn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from wn import WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
